{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function area\n",
    "Parameters summary function come from stackoverflowï¼š  <br/>\n",
    "https://stackoverflow.com/questions/42480111/model-summary-in-pytorch\n",
    "\n",
    "'''\n",
    "Note1.<br/>\n",
    "def _addindent(s_, numSpaces):\n",
    "    s = s_.split('\\n')\n",
    "    # dont do anything for single-line stuff\n",
    "    if len(s) == 1:\n",
    "        return s_\n",
    "    first = s.pop(0)\n",
    "    s = [(numSpaces * ' ') + line for line in s]\n",
    "    s = '\\n'.join(s)\n",
    "    s = first + '\\n' + s\n",
    "    return s\n",
    "\n",
    "Note2. np.prod: Return the product of array elements over a given axis.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function 1\n",
    "from torch.nn.modules.module import _addindent\n",
    "def torch_summarize(model, show_weights=True, show_parameters=True):\n",
    "    \"\"\"Summarizes torch model by showing trainable parameters and weights.\"\"\"\n",
    "    total_params = 0\n",
    "    tmpstr = model.__class__.__name__ + ' :\\n' #Pring the object name\n",
    "    for key, module in model._modules.items():\n",
    "        # if it contains layers let call it recursively to get params and weights\n",
    "        if type(module) in [\n",
    "                    torch.nn.modules.container.Container,\n",
    "                    torch.nn.modules.container.Sequential\n",
    "                            ]:\n",
    "            modstr = torch_summarize(module)\n",
    "        else:\n",
    "            modstr = module.__repr__()\n",
    "        modstr = _addindent(modstr, 2) # Note1\n",
    "        \n",
    "        params = sum([np.prod(p.size()) for p in module.parameters()]) # Note2\n",
    "        weights = tuple([tuple(p.size()) for p in module.parameters()])\n",
    "        total_params = total_params + params \n",
    "        tmpstr += '  (' + key + '): ' + modstr \n",
    "        if show_weights:\n",
    "            tmpstr += ', weights={}'.format(weights)\n",
    "        if show_parameters:\n",
    "            tmpstr +=  ', parameters={}'.format(params)\n",
    "        tmpstr += '\\n------------------------------------------------------\\n'\n",
    "    tmpstr = tmpstr + ')'\n",
    "    tmpstr = tmpstr + ' \\n##Total Parameters = {} '.format(total_params)\n",
    "    return tmpstr\n",
    "\n",
    "\n",
    "# Function 2\n",
    "def show_batch(batch):\n",
    "    '''Show image of one batch'''\n",
    "    im = torchvision.utils.make_grid(batch)\n",
    "    plt.imshow(np.transpose(im.numpy(), (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load MNIST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 200 # setting batch size\n",
    "transform = transforms.ToTensor() # Transform them to tensors\n",
    "\n",
    "# Load and transform data\n",
    "trainset = torchvision.datasets.MNIST('./mnist', train=True, download=True, transform=transform)\n",
    "#testset = torchvision.datasets.MNIST('./mnist', train=False, download=True, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "#testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch shape:  torch.Size([200, 1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "#print('Labels: ', list(labels))\n",
    "print('Batch shape: ', images.size())\n",
    "show_batch(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Shallow Model\n",
    "How to get the size of feature map: <br>\n",
    "Output H = 1 + (input H + 2Panding - Filter H)/Stride <br>\n",
    "Output W = 1 + (input W + 2Panding - Filter W)/Stride <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Shallow_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Shallow_model, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=105, kernel_size=3, stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        \n",
    "        # fully connected layer\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(in_features=13*13*105, out_features=10))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        return F.log_softmax(out) #last layer is softmax layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the model & loss function & optimizer\n",
    "SNet = Shallow_model()\n",
    "loss_func = nn.CrossEntropyLoss(size_average=False)\n",
    "optimizer = torch.optim.Adam(SNet.parameters(), lr=1e-3, betas=(0.9, 0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shallow_model :\n",
      "  (layer1): Sequential :\n",
      "    (0): Conv2d(1, 105, kernel_size=(3, 3), stride=(1, 1)), weights=((105, 1, 3, 3), (105,)), parameters=1050\n",
      "  ------------------------------------------------------\n",
      "    (1): ReLU(inplace), weights=(), parameters=0\n",
      "  ------------------------------------------------------\n",
      "    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), ceil_mode=False), weights=(), parameters=0\n",
      "  ------------------------------------------------------\n",
      "  ) \n",
      "  ##Total Parameters = 1050 , weights=((105, 1, 3, 3), (105,)), parameters=1050\n",
      "------------------------------------------------------\n",
      "  (fc1): Sequential :\n",
      "    (0): Linear(in_features=17745, out_features=10, bias=True), weights=((10, 17745), (10,)), parameters=177460\n",
      "  ------------------------------------------------------\n",
      "  ) \n",
      "  ##Total Parameters = 177460 , weights=((10, 17745), (10,)), parameters=177460\n",
      "------------------------------------------------------\n",
      ") \n",
      "##Total Parameters = 178510 \n"
     ]
    }
   ],
   "source": [
    "print(torch_summarize(SNet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eric/anaconda3/envs/pytorch_gpu/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [3800/60000 (6%)]\tLoss: 124.736107,  Accumulation batch acc=60.8%\n",
      "Train Epoch: 1 [7800/60000 (13%)]\tLoss: 76.771278,  Accumulation batch acc=74.0%\n",
      "Train Epoch: 1 [11800/60000 (20%)]\tLoss: 76.151733,  Accumulation batch acc=79.6%\n",
      "Train Epoch: 1 [15800/60000 (26%)]\tLoss: 47.040329,  Accumulation batch acc=82.9%\n",
      "Train Epoch: 1 [19800/60000 (33%)]\tLoss: 44.093231,  Accumulation batch acc=85.0%\n",
      "Train Epoch: 1 [23800/60000 (40%)]\tLoss: 39.303097,  Accumulation batch acc=86.5%\n",
      "Train Epoch: 1 [27800/60000 (46%)]\tLoss: 29.995150,  Accumulation batch acc=87.7%\n",
      "Train Epoch: 1 [31800/60000 (53%)]\tLoss: 46.388893,  Accumulation batch acc=88.6%\n",
      "Train Epoch: 1 [35800/60000 (60%)]\tLoss: 27.591980,  Accumulation batch acc=89.4%\n",
      "Train Epoch: 1 [39800/60000 (66%)]\tLoss: 39.556881,  Accumulation batch acc=90.0%\n",
      "Train Epoch: 1 [43800/60000 (73%)]\tLoss: 29.579845,  Accumulation batch acc=90.5%\n",
      "Train Epoch: 1 [47800/60000 (80%)]\tLoss: 36.751682,  Accumulation batch acc=91.0%\n",
      "Train Epoch: 1 [51800/60000 (86%)]\tLoss: 25.697157,  Accumulation batch acc=91.4%\n",
      "Train Epoch: 1 [55800/60000 (93%)]\tLoss: 30.895018,  Accumulation batch acc=91.8%\n",
      "Train Epoch: 1 [59800/60000 (100%)]\tLoss: 25.055357,  Accumulation batch acc=92.1%\n",
      "Train Epoch: 2 [3800/60000 (6%)]\tLoss: 13.464671,  Accumulation batch acc=97.5%\n",
      "Train Epoch: 2 [7800/60000 (13%)]\tLoss: 17.068445,  Accumulation batch acc=97.5%\n",
      "Train Epoch: 2 [11800/60000 (20%)]\tLoss: 15.550008,  Accumulation batch acc=97.6%\n",
      "Train Epoch: 2 [15800/60000 (26%)]\tLoss: 24.389906,  Accumulation batch acc=97.5%\n",
      "Train Epoch: 2 [19800/60000 (33%)]\tLoss: 22.837128,  Accumulation batch acc=97.5%\n",
      "Train Epoch: 2 [23800/60000 (40%)]\tLoss: 16.299644,  Accumulation batch acc=97.4%\n",
      "Train Epoch: 2 [27800/60000 (46%)]\tLoss: 10.810911,  Accumulation batch acc=97.5%\n",
      "Train Epoch: 2 [31800/60000 (53%)]\tLoss: 13.949410,  Accumulation batch acc=97.5%\n",
      "Train Epoch: 2 [35800/60000 (60%)]\tLoss: 17.886375,  Accumulation batch acc=97.5%\n",
      "Train Epoch: 2 [39800/60000 (66%)]\tLoss: 12.107552,  Accumulation batch acc=97.5%\n",
      "Train Epoch: 2 [43800/60000 (73%)]\tLoss: 7.118986,  Accumulation batch acc=97.6%\n",
      "Train Epoch: 2 [47800/60000 (80%)]\tLoss: 21.743937,  Accumulation batch acc=97.6%\n",
      "Train Epoch: 2 [51800/60000 (86%)]\tLoss: 21.522108,  Accumulation batch acc=97.6%\n",
      "Train Epoch: 2 [55800/60000 (93%)]\tLoss: 14.585538,  Accumulation batch acc=97.7%\n",
      "Train Epoch: 2 [59800/60000 (100%)]\tLoss: 10.544326,  Accumulation batch acc=97.7%\n"
     ]
    }
   ],
   "source": [
    "# Running Model \n",
    "loss_old = 0.01\n",
    "check_time = 0\n",
    "num_of_epoch = 10\n",
    "\n",
    "iters = 0\n",
    "for epoch in range(num_of_epoch):\n",
    "    correct = 0\n",
    "    for i, (images, labels) in enumerate(trainloader):\n",
    "        # convert tensor to Variable\n",
    "        images = Variable(images)\n",
    "        labels = Variable(labels)\n",
    "\n",
    "        # clear gradients w.r.t parameters\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward pass\n",
    "        outputs = SNet(images)\n",
    "\n",
    "        # calculate loss\n",
    "        loss = loss_func(outputs, labels)\n",
    "\n",
    "        # get gradient w.r.t parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        iters += 1\n",
    "        \n",
    "        # Accuracy (each batch)\n",
    "        pred = outputs.data.max(1)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(labels.data).cpu().sum()\n",
    "        Acc = correct / ((i+1)*BATCH_SIZE) * 100\n",
    "        if iters % 20 == 0:     \n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f},  Accumulation batch acc={:.1f}%'.format(\n",
    "                    epoch+1, i * len(images), len(trainloader.dataset),\n",
    "                    100. * i / len(trainloader), loss.data[0], Acc))\n",
    "    if Acc >= 97: break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Model\n",
    "How to get the size of feature map: <br>\n",
    "Output H = 1 + (input H + 2Panding - Filter H)/Stride <br>\n",
    "Output W = 1 + (input W + 2Panding - Filter W)/Stride <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter number of Conv layers\n",
    "fil = [30, 35, 30]\n",
    "\n",
    "class Deep_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Deep_model, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=fil[0], kernel_size=5, stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2) )\n",
    "        \n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=fil[0], out_channels=fil[1], kernel_size=3, stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2) )\n",
    "        \n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=fil[1], out_channels=fil[2], kernel_size=1, stride=1),\n",
    "            nn.ReLU(inplace=True))\n",
    "            #nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        \n",
    "        \n",
    "        # fully connected layer\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(in_features=5*5*fil[2], out_features=200),\n",
    "            nn.ReLU(inplace=True))\n",
    "    \n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(in_features=200, out_features=80),\n",
    "            nn.ReLU(inplace=True))\n",
    "        \n",
    "        \n",
    "\n",
    "        self.fc3 = nn.Sequential(nn.Linear(in_features=80, out_features=10))\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer3(self.layer2(self.layer1(x)))\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc3(self.fc2(self.fc1(out)))\n",
    "        return F.log_softmax(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the model & loss function & optimizer\n",
    "DNet = Deep_model()\n",
    "loss_func = nn.CrossEntropyLoss(size_average=False)\n",
    "optimizer = torch.optim.Adam(DNet.parameters(), lr=1e-3, betas=(0.9, 0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep_model :\n",
      "  (layer1): Sequential :\n",
      "    (0): Conv2d(1, 30, kernel_size=(5, 5), stride=(1, 1)), weights=((30, 1, 5, 5), (30,)), parameters=780\n",
      "  ------------------------------------------------------\n",
      "    (1): ReLU(inplace), weights=(), parameters=0\n",
      "  ------------------------------------------------------\n",
      "    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), ceil_mode=False), weights=(), parameters=0\n",
      "  ------------------------------------------------------\n",
      "  ) \n",
      "  ##Total Parameters = 780 , weights=((30, 1, 5, 5), (30,)), parameters=780\n",
      "------------------------------------------------------\n",
      "  (layer2): Sequential :\n",
      "    (0): Conv2d(30, 35, kernel_size=(3, 3), stride=(1, 1)), weights=((35, 30, 3, 3), (35,)), parameters=9485\n",
      "  ------------------------------------------------------\n",
      "    (1): ReLU(inplace), weights=(), parameters=0\n",
      "  ------------------------------------------------------\n",
      "    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), ceil_mode=False), weights=(), parameters=0\n",
      "  ------------------------------------------------------\n",
      "  ) \n",
      "  ##Total Parameters = 9485 , weights=((35, 30, 3, 3), (35,)), parameters=9485\n",
      "------------------------------------------------------\n",
      "  (layer3): Sequential :\n",
      "    (0): Conv2d(35, 30, kernel_size=(1, 1), stride=(1, 1)), weights=((30, 35, 1, 1), (30,)), parameters=1080\n",
      "  ------------------------------------------------------\n",
      "    (1): ReLU(inplace), weights=(), parameters=0\n",
      "  ------------------------------------------------------\n",
      "  ) \n",
      "  ##Total Parameters = 1080 , weights=((30, 35, 1, 1), (30,)), parameters=1080\n",
      "------------------------------------------------------\n",
      "  (fc1): Sequential :\n",
      "    (0): Linear(in_features=750, out_features=200, bias=True), weights=((200, 750), (200,)), parameters=150200\n",
      "  ------------------------------------------------------\n",
      "    (1): ReLU(inplace), weights=(), parameters=0\n",
      "  ------------------------------------------------------\n",
      "  ) \n",
      "  ##Total Parameters = 150200 , weights=((200, 750), (200,)), parameters=150200\n",
      "------------------------------------------------------\n",
      "  (fc2): Sequential :\n",
      "    (0): Linear(in_features=200, out_features=80, bias=True), weights=((80, 200), (80,)), parameters=16080\n",
      "  ------------------------------------------------------\n",
      "    (1): ReLU(inplace), weights=(), parameters=0\n",
      "  ------------------------------------------------------\n",
      "  ) \n",
      "  ##Total Parameters = 16080 , weights=((80, 200), (80,)), parameters=16080\n",
      "------------------------------------------------------\n",
      "  (fc3): Sequential :\n",
      "    (0): Linear(in_features=80, out_features=10, bias=True), weights=((10, 80), (10,)), parameters=810\n",
      "  ------------------------------------------------------\n",
      "  ) \n",
      "  ##Total Parameters = 810 , weights=((10, 80), (10,)), parameters=810\n",
      "------------------------------------------------------\n",
      ") \n",
      "##Total Parameters = 178435 \n"
     ]
    }
   ],
   "source": [
    "print(torch_summarize(DNet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eric/anaconda3/envs/pytorch_gpu/lib/python3.6/site-packages/ipykernel_launcher.py:44: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [3800/60000 (6%)]\tLoss: 366.770233,  Accumulation batch acc=28.1%\n",
      "Train Epoch: 1 [7800/60000 (13%)]\tLoss: 135.742355,  Accumulation batch acc=49.6%\n",
      "Train Epoch: 1 [11800/60000 (20%)]\tLoss: 93.916733,  Accumulation batch acc=61.4%\n",
      "Train Epoch: 1 [15800/60000 (26%)]\tLoss: 82.038795,  Accumulation batch acc=67.9%\n",
      "Train Epoch: 1 [19800/60000 (33%)]\tLoss: 51.646832,  Accumulation batch acc=72.2%\n",
      "Train Epoch: 1 [23800/60000 (40%)]\tLoss: 70.576019,  Accumulation batch acc=75.4%\n",
      "Train Epoch: 1 [27800/60000 (46%)]\tLoss: 29.793171,  Accumulation batch acc=77.9%\n",
      "Train Epoch: 1 [31800/60000 (53%)]\tLoss: 19.501791,  Accumulation batch acc=80.0%\n",
      "Train Epoch: 1 [35800/60000 (60%)]\tLoss: 24.378628,  Accumulation batch acc=81.7%\n",
      "Train Epoch: 1 [39800/60000 (66%)]\tLoss: 29.607759,  Accumulation batch acc=83.1%\n",
      "Train Epoch: 1 [43800/60000 (73%)]\tLoss: 31.054874,  Accumulation batch acc=84.3%\n",
      "Train Epoch: 1 [47800/60000 (80%)]\tLoss: 23.495838,  Accumulation batch acc=85.3%\n",
      "Train Epoch: 1 [51800/60000 (86%)]\tLoss: 14.021351,  Accumulation batch acc=86.1%\n",
      "Train Epoch: 1 [55800/60000 (93%)]\tLoss: 22.884119,  Accumulation batch acc=86.8%\n",
      "Train Epoch: 1 [59800/60000 (100%)]\tLoss: 17.105442,  Accumulation batch acc=87.5%\n",
      "Train Epoch: 2 [3800/60000 (6%)]\tLoss: 14.681189,  Accumulation batch acc=97.0%\n",
      "Train Epoch: 2 [7800/60000 (13%)]\tLoss: 10.660532,  Accumulation batch acc=97.2%\n",
      "Train Epoch: 2 [11800/60000 (20%)]\tLoss: 24.991585,  Accumulation batch acc=97.3%\n",
      "Train Epoch: 2 [15800/60000 (26%)]\tLoss: 16.203720,  Accumulation batch acc=97.3%\n",
      "Train Epoch: 2 [19800/60000 (33%)]\tLoss: 19.821259,  Accumulation batch acc=97.3%\n",
      "Train Epoch: 2 [23800/60000 (40%)]\tLoss: 10.361759,  Accumulation batch acc=97.3%\n",
      "Train Epoch: 2 [27800/60000 (46%)]\tLoss: 23.170311,  Accumulation batch acc=97.3%\n",
      "Train Epoch: 2 [31800/60000 (53%)]\tLoss: 23.077343,  Accumulation batch acc=97.3%\n",
      "Train Epoch: 2 [35800/60000 (60%)]\tLoss: 6.488492,  Accumulation batch acc=97.3%\n",
      "Train Epoch: 2 [39800/60000 (66%)]\tLoss: 20.268070,  Accumulation batch acc=97.4%\n",
      "Train Epoch: 2 [43800/60000 (73%)]\tLoss: 8.840987,  Accumulation batch acc=97.4%\n",
      "Train Epoch: 2 [47800/60000 (80%)]\tLoss: 27.512354,  Accumulation batch acc=97.4%\n",
      "Train Epoch: 2 [51800/60000 (86%)]\tLoss: 18.465469,  Accumulation batch acc=97.5%\n",
      "Train Epoch: 2 [55800/60000 (93%)]\tLoss: 5.769819,  Accumulation batch acc=97.5%\n",
      "Train Epoch: 2 [59800/60000 (100%)]\tLoss: 5.859987,  Accumulation batch acc=97.6%\n"
     ]
    }
   ],
   "source": [
    "iters = 0\n",
    "for epoch in range(10):\n",
    "    correct = 0\n",
    "    for i, (images, labels) in enumerate(trainloader):\n",
    "        # convert tensor to Variable\n",
    "        images = Variable(images)\n",
    "        labels = Variable(labels)\n",
    "\n",
    "        # clear gradients w.r.t parameters\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward pass\n",
    "        outputs = DNet(images)\n",
    "\n",
    "        # calculate loss\n",
    "        loss = loss_func(outputs, labels)\n",
    "\n",
    "        # get gradient w.r.t parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        iters += 1\n",
    "        # Accuracy (each batch)\n",
    "        pred = outputs.data.max(1)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(labels.data).cpu().sum()\n",
    "        Acc = correct / ((i+1)*BATCH_SIZE) * 100\n",
    "        if iters % 20 == 0:     \n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f},  Accumulation batch acc={:.1f}%'.format(\n",
    "                    epoch+1, i * len(images), len(trainloader.dataset),\n",
    "                    100. * i / len(trainloader), loss.data[0], Acc))\n",
    "    if Acc >= 97: break     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
